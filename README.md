Вначале мы провели первичный EDA - выявили размера тренировочного и тестового датасетов - (6999 и 1000 строк соответственно). В каждом датасете 13 признаков<br>
Увидели, что в тестовом датасете есть пропуски в столбцах mileage, engine, max_power, torque и seats<br>
Также, в тестовом датасете были обнаружены дубликаты<br>

Далее, мы построили отчет по тестовому датасету с помощью ydata_profiling, итоги анализа следующие:<br>
В данных для обучения 6999 строк, присутствуют пропуски и дубликаты<br>

В поле name отсутствуют пропущенные значения, 1924 уникальных объекта<br>
В датасете представлены данные по АМ, которые были выпущены в период 1983-2020 гг. Для каждой АМ указан год выпуска<br>
Цена продажи варьирует от 29999 до 10000000, пропуски отсутствуют<br>
Средний пробег АМ - 69585 км. Для каждой АМ указан пробег<br>
Для каждой АМ указан тип топлива, которых всего 4 (Diesel, Petrol, CNG, LPG). Доля дизельных АМ превышает долю бензиновых АМ. Для каждой АМ указан тип топлива<br>
Для каждой АМ указан тип продавца. Доля частных лиц значимо превышает долю дилеров<br>
Для каждой АМ указан тип корбки передач. Доля ручной коробки передач превышает долю автоматической коробки передач<br>
Доля каждой АМ указано кол-во владельцев. Наибольшая доля АМ с одним владельцем<br>
Есть пропуски данных в поле с расходом топлива, которые отображаются как кол-во км на 1 л<br>
Не для каждой АМ указан объем двигателя, мощность и крутящий момент<br>
Также есть пропуски в поле с количеством сидений<br>

Можно увидеть сильную прямую взаимосвязь между следующими признаками:<br>
* Ценой продажи и годом выпуска АМ
* Ценой продажи и трансмиссией

Можно увидеть сильную обратную взаимосвязь между следующими признаками:<br>
* Год выпуска АМ и пробег
* Год выпуска АМ и цена продажи
* В датасете присутствует 493 уникальных строки с дубликатами
* Всего дубликатов в датасете - 985 строк

Анализируем статистики датасета и получаем следующие выводы:<br>
Различия между средней и медианой внутри датасета говорят об отклонении от нормального распределения<br>
В train и test наибольшее отклонение от нормального распределения в поле km driven<br>
Значимых отличий в среднем и медиане между train и test нет. Это говорит о том, что разделение данных на train и test проведено корректно и можно ожидать, что оценки качества модели и ошибки на train и test будут похожими<br>

Затем, мы удаляем дубликаты из тестового датасета<br>
Далее, мы корректируем оба датасета - тестовый и тренировочный<br>
Мы убираем единицы измерения из mileage, engine и max_power, приводим их к типу float<br>
Предобрабатываем torque - делим на два признака torque и max_torque_rpm<br>

Далее, мы заполняем пропуски в обоих датасетах медианными значениями вещественных признаков из тренировочного датасета<br>

Анализируем как изменилось распределение тренировочного датасета после наших изменений:<br>
Поле seats:<br>
Было: Среднее: 5,41, Отклонение: 0,97<br>
Стало: Среднее: 5,87, Отклонение: 2,57<br>
В случае наличия значимого количества пропусков и заполнения медианой распределение сдвинется в сторону нормального распределения. Также это может уменьшить среднее отклонение. В нашем случае оно увеличилось из-за удаления дублей<br>
В случае заполнения средним значением, распределение сдвинется в сторону выбросов<br>

Далее, мы строим pairplot и делаем следующие выводы на их основании:<br>
На основе графиков можно увидеть что происходит с целевой переменной при изменении одного из признаков<br>
Например, можно заметить, что при уменьшении года выпуска АМ, ее стоимость снижается<br>
Также можно заметить, что при увеличении max_power увеличивается стоимость АМ<br>

На трейне незначительно отличается распределение на графике между стоимостью АМ и пробегом АМ<br>
В остальном, распределения на трейне и тесте похожи<br>

Затем, мы смотрим на коррееляцию между признаками и делаем следующие выводы:<br>
Наименьшая корреляция наблюдается между признаками:<br>
* max_power и km_driven
* max_torque_rpm и year

Сильная положительная связь наблюдается между:<br>
* engine и max_power
* engine и torque
* max_power и torque
Между годом выпуска и пробегом существует умеренная обратная связь. Это говорит о том, для части данных будет справедливо утверждение, что при уменьшении года выпуска АМ увеличивается пробег АМ, но говорить точно мы об этом не можем<br>

Затем, мы смотрим различия между коэффициентами корреляции Пирсона и Спирмена<br>
Можно увидеть, что есть различия между корреляциями Пирсона и Спирмена<br>
Например, рассмотрим влияние показателей на целевую переменную:<br>

Корреляция Спирмена > корреляции Пирсона для year, torque, seats. Следовательно, между показателями существует нелинейная связь<br>

Также, мы исследуем тестовые данные на выбросы, строим boxplotпо вещественным признакам<br>
Исследуем данные на выбросы, построим boxplot по каждой числовой переменной<br>
Видим, что по переменым year, selling_price, mileage, engine, max_power есть выбросы, которые могут повлиять на качество модели<br>
seats мы не рассматриваем, так как у него мало уникальных значений и признак может быть отнесен к категориальным<br>

После анализа данных, мы переходим к построению моделей<br>

Строим модель линейной регрессии и смотрим ее результаты<br>
По модели обученной на трейне видно, что она объясняет 59,6% дисперсии<br>
Для теста r^2 отличается не сильно. Это ознаначает, что модель не переобучена и данные для трейна и теста разделены корректно<br>
По значению MSE сложно сделать выводы о качестве модели<br>

Также мы анализируем отличия между R^2 и R^2 - adjusted<br>
R^2 - adjusted применяется в многофакторной регрессии для оценки влияния признаков на дисперсию<br>
Например, если при добавлении нового признака R^2 adjusted снизилась, то данный признак не вносит значимого вклада в модель<br>
Таким образом, можно оставить в датасете только значимые признаки<br>

После этого, мы стандартизируем признаки с помощью StandatdScaler и вновь строим модель линейной регрессии<br>
Метрики MSE и R^2 практически не изменились<br>

На основании анализа коэффициентов модели можно сделать вывод о том, что наиболее информативным признаком оказался max_power, он вносит наибольший вклад в целевую переменную<br>

Далее, мы применяем регуляризацию - строим Лассо-регрессию<br>
MSE и R^2 вновь не изменились<br>
L1 регуляризация не занулила коэффициенты. Следовательно, каждый из показателей вносит значимый вклад в объяснение дисперсии<br>

Далее, с помощью gridSearchCV 10 фолдами подбираем оптимальные гиперпараметры для модели Лассо-регрессии<br>
GridSearch обучил alpha*cv = 100 моделей<br>
Каждый параметр в param_grid - это список гиперпараметров, которые мы применяем к модели<br>
В нашем случае, alpha - это константа, которая умножается на штраф и увеличивает силу регуляризации (больше alpha - больше сила регуляризации)<br>
Лучший коэффцициент регуляризации - alpha=1000. Веса показателей не занулились<br>

Затем, с помощью GridSearchCV мы находим оптимальные гиперпараметры для модели ElasticNet<br>
GridSearch обучил alpha*l1_ratio*cv = 1100 моделей<br>
Лучшая модель - это модель Лассо регрессии (l1_ratio=1) с alpha = 1000<br>

Модель с L0 регуляризацией построить не удалось<br>

Далее, мы работаем с категориальными фичами<br>
Мы предобрабатываем столбец name, в котором содержатся данные о марке, модели и комплектации<br>
В связи с большой вариативностью описания внутри пораметра name, удалось корректно вытащить только марку и модель АМ<br>

Мы кодируем категориальные параметры с помощью OneHotEncoding<br>
В процессе OHE мы преобразуем категориальные признаки в бинарные. Количество уникальных элементов категориальных признаков не должно быть очень большим<br>
Мы используем n-1 столбцов, так как если брать n столбцов, то будет возникать линейная зависимость<br>
Например, если у категории Grade есть значения: Good, Nice и Great, то после OHE мы получаем 2 столбца (например, Grade_Good, Great_Nice). В случае, если Grade_Good = False и Grade_Nice = False, то мы понимаем, что поле Grade_Great имело бы значение True, несмотря на то, что в явном виде оно отсутствует<br>
Мы можем удалить незначимые признаки<br>

После этого, мы строим модель с L2 регуляризацией - Ridge-регрессию с учетом OHE<br>
Получаем R^2=0.89, что является хорошим показателем<br>

После различных преобразований датасета и применения различных моделей мы можем построить одну, которая будет давать лучший прогноз<br>

Мы преобразуем признаки torque, mileage, engine, max_power, приводя их к числовому типу<br>
Извлекаем из поля name марку и модель АМ<br>

Далее, мы генерируем новые признаки на основе уже существующих, а именно:<br>
* Возраст АМ
* Средний пробег в год
* Мощность на объем двигателя
* Квадрат года
* Категория возраста АМ
* Категория АМ по мощности

После этого, мы обрабатываем числовые признаки:<br>
* Заполняем пропуски медианой
* Масштабируем с помощью StandardScaler

Обрабатываем категориальные признаки:<br>
* Заполняем пропуски значением NA
* Делаем OneHotEncoding

После этого строим ElasticNet с alpha=0.0001 и l1_ratio=0.9<br>

На тестовых данных получаем средующий результат:<br>
* r2: 0.9202955882333865 (то есть, модель объясняет 92.03% дисперсии)
* MSE: 45816371893.814255

Построим для модели бизнес метрики:<br>
Считаем долю АМ, у которых прогнозная цена отличается от реальной цены менее, чем на 10%<br>
Получаем, что для 32.4% АМ прогнозная цена отличается от реальной менее, чем на 10%<br>

Также, построим метрику, которая будет отражать среднее отклонение между прогнозной и реальной ценами<br>
В случае, если прогнозная цена ниже реальной, то в таком случае штрафовать будем в 2 раза больше<br>

Напишем api с помощью FastApi. Реализуем два сценария:<br>
1.Отправляем json с информацией об одном АМ и получаем прогнозное значение цены
2.Отправляем csv файл с данными об АМ и получаем обратно csv файл с еще одной колонкой - прогнозной ценой АМ

Тестирование первого сценария в Postman:<br>
Отправляем json по одной АМ<br>
![Alt text](https://github.com/IvanMakhrov/ML_HW1/blob/c96ccb6632e4f98ae811a5ce52c21862ce724fc5/images/predict_item_postman.png?raw=true)

Тестирование первого сценария на Python:<br>
Делаем 5 итераций по отправке json<br>
![Alt text](https://github.com/IvanMakhrov/ML_HW1/blob/main/images/predict_item_python.png?raw=true)

Тестирование второго сценария в Postman:<br>
Отправляем csv файл и получаем обратно его же с новой колонкой - пронозной ценой АМ<br>
![Alt text](https://github.com/IvanMakhrov/ML_HW1/blob/main/images/predict_items_postman.png?raw=true)

Тестирование второго сценария на Python:<br>
Отправляем csv файл и получаем его обратно с прогнозной ценой АМ<br>
Трансформируем его в df и смотрим первые 5 значений и статистику<br>
![Alt text](https://github.com/IvanMakhrov/ML_HW1/blob/main/images/predict_items_python.png?raw=true)
